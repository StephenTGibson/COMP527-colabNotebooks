{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "K-nearest neighbour classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StephenTGibson/COMP527-colabNotebooks/blob/main/K_nearest_neighbour_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDacRLhlB53U"
      },
      "source": [
        "# K-nearest neighbour classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnqS7R24nirp"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhPO1WqoB53Z"
      },
      "source": [
        "When developing algorithms it is often desirable to have datasets for testing purposes. When there is no access to a suitable dataset, sometimes it is convenient to generate synthetic data. In this tutorial, we will  \n",
        "1. create synthetic datasets consisting of two classes of objects;\n",
        "2. develop the k-NN algorithm;\n",
        "3. evaluate the algorithm's ability to separate the two classes of objects."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81Goubf2B53Z"
      },
      "source": [
        "## Excercise 1. Create synthetic dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-sUJxXbB53Z"
      },
      "source": [
        "We would like to generate training and validation datasets for binary classification. For visualisation purposes, we will assume that our objects have 2 numeric features. We would like to generate 2 \"cloulds\" of points on the plane corresponding to the positive and negative objects respectively. To do this, one can generate random points from a [multivariate normal distribution](https://en.wikipedia.org/wiki/Multivariate_normal_distribution) (function $\\texttt{np.random.multivariate_normal}$). For example, $\\texttt{np.random.multivariate_normal([a,b], [[1,0],[0,1]], N)}$ will generate a set on N points scattered around the *mean* point $(a,b)$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6MUT2BDB53Z"
      },
      "source": [
        "1. Create two sets of $N=10$ points. The first set scattered around the point $(0,0)$ and the second scattered around the point $(2,2)$. These sets of points will correspond to the positive and the negative class respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQuhgi6iB53Z"
      },
      "source": [
        "N = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqwTQ2lOB53a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVP933PjB53a"
      },
      "source": [
        "2. Plot the generated sets of points. Use different colours or markers for different classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNd5TGBuB53a"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbsWKePOB53a"
      },
      "source": [
        "3. Split each of the sets into equal train and validation portions. As a result you should have four sets: \n",
        "- positive object in the train dataset;\n",
        "- positive object in the validation dataset;\n",
        "- negataive object in the train dataset;\n",
        "- negataive object in the validation dataset;\n",
        "\n",
        "To confirm that the sets have equal numbers of objects, print the number of elements in each set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4M8bjuyfnisE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inM3_7qvB53b"
      },
      "source": [
        "4. Add an extra freature (representing the class label: +1 for the positive class, -1 for the negative class) to the train and validation instances. As a result you will have two datasets, each consisting of tuples (label, instance)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCYl3vQWnisS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yq9AGUOTB53b"
      },
      "source": [
        "## Excercise 2. Develop the k-NN algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRyCHG07B53b"
      },
      "source": [
        "Implement k-NN prediction function that uses the training dataset from the previous exercise. Use cosine similarity as a \"measure of distance\". The larger the similarity between two objects, the closer the objects are to each other."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wECY1E1jnisj"
      },
      "source": [
        "1. Create the cosine similarity function that will be used in the k-NN prediction function to find the neighbours. The function should take two vectors as input and output the cosine similarity between the vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6VfNVJTniso"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D15_YJKXnist"
      },
      "source": [
        "2. Implement a function that predicts the class of a validation instance using the k-NN algorithm. The function should take a validation instance and the parameter $k$ as input, and output predicted class of the validation instance (+1 or -1)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKh9Ze2Znisw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OeZE7N5B53c"
      },
      "source": [
        "## Excercise 3. Evaluate the algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzC00JZmB53c"
      },
      "source": [
        "1. Implement $\\texttt{kNNaccuracy}$ function that takes the parameter $k$ and the validation dataset as input and output the accuracy of the k-NN algorithm on the validation dataset. Use the function to compute the accuracy of prediciton of the k-NN classifier on the validation dataset, when $k = 5$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40dffWDgnitG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kecwL98AB53c"
      },
      "source": [
        "2. Generate new datasets with $N=100$. Compute accuracies of k-NN for all odd $k$ from 1 to 99. Plot k-NN accuracy versus $k$. What is the best value of $k$ for the validation dataset?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkQWGaFIB53c"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWoB_tlonitK"
      },
      "source": [
        "3. Conduct further experiments:\n",
        "    * change the value of $k$\n",
        "    * increase the number of instances $N$ (make sure that $N$ is even)\n",
        "    * separate or bring together the two classes by adjusting the means of the two Gaussians.\n",
        "\n",
        "How does the accuracy vary in each case?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4-c2DvxB53c"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}